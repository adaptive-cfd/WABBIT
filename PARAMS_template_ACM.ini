;------------------------------------------------------------
;------------ WABBIT PARAMETER FILE TEMPLATE ----------------
;------------------------------------------------------------
; if you add new parameters, add them here.
; note values have to be declared "value=0;", with equal sign (=) and semicolon (;)


[Domain]
; 2D or 3D problem?
dim=3;
; box size of computational domain. [Lx Ly Lz]
domain_size=4 4 4;
; synchronization (on/off)on [x y z] domain boundaries
; (off (NON-PERIODIC): 0/false/yes | on (PERIODIC): 1/true/no)
periodic_BC=1 1 1;
; --- SINCE Apr 2023, SYMMETRY BC IS BROKEN ---
; symmetry BC. If a problem has e.g, x symmetry (mirror axis is then the y-axis), you'd set 1 0 here.
; symmetry still goes with periodicity in the code: we solve a symmetric periodic problem (cosine-transform)
; this implies all BC in symmetric directions are treated symmetrically (so, at x=const=0 and x=const=Lx)
; While it is possible to also set dirichlet BC on either, we have not currently implemented it.
; Hint: ensure to not impose a meanflow in symmetric directions! Default: (.not. periodic_BC)
symmetry_BC=0 0 0;
; symmetry comes in two ways: for scalars (phi, pressure, density) and tangential velocity components (for
; y symmetry, this would be ux, uz but NOT uy), we simply mirror the data. For the normal component (here: uy)
; we mirror the component, invert the sign and also have to set uy=0 right on the line of symmetry.
; Tell the code what is a scalar and which are vector components. For 2D ACM this would be x y 0, for 3D ACM this would be x y z 0,
; for 3D compressible Navier_Stokes this would be 0 x y z 0 (0: scalar). The length of this vector equals number_equations. Default: 0 for all
symmetry_vector_component=



[Wavelet]
; which wavelet to use: CDF20, CDF22, CDF40, CDF42, CDF44, CDF46, CDF60 or CDF62
; required number of ghost nodes: 2, 3, 4, 5, 7, 9, 6, 7
wavelet=CDF44;
cvs=0;


[Blocks]
; size of each block, must be even, if given one value this is used
; for all directions, or specify value for each direction
number_block_nodes=20 20 20;
; ghost nodes for each block. If you leave it empty, it will be set according
; to the wavelet. (see Wavelet::wavelet). If the discretization scheme requires
; more ghost nodes, set the value here.
number_ghost_nodes=;
; For the right hand side, often less ghost nodes are required than for the wavelet, specify here.
; For a 4th order FD code, this is 2 (FD4) or 3 (TW4). 2nd order is 1. Default=number_ghost_nodes
number_ghost_nodes_rhs=;
; number of equations / components of state vector. Note you have to properly
; adjust this value for the physics module that you use.
; ACM: 3 (2D), 4 (3D) +  nscalars
; Convection: 1 (2D /3D)
number_equations=3;
; threshold value for thresholding wavelet coefficients
eps=1e-3;
; WABBIT uses interpolating, biorthogonal wavelets. These wavelets are, by default, normalized in the Linfty
; norm. That means setting a threshold eps=1.0e-3, we guarantee that the error is < 1.0e-3 in Linfty norm.
; For denoising, we rather need to control the L2 error, because Donohos work is applicable only to the L2 norm.
; For CVS finally, which mimicks applying the denoising to vorticity, we need to control the H1 norm.
; [Linfty (default), L2, H1]
eps_norm=Linfty;
; treelevel bounds: determine the highest (max_treelevel) and lowest (min_treelevel) refinement
; level of blocks. With each refinement level the grid gets refined by a factor of two. The maximum
; resolution at max_treelevel is dx = 2^-max_treelevel * L / Bs (L:domain size, Bs: blocksize)
max_treelevel=6;
; sometimes you want to restrict the minimum refinement as well, for example if we run equidistant
; simulations (which is quite rare!): in that case, max_treelevel = min_treelevel. coarsening beyond
; min_treelevel is not allowed.
min_treelevel=1;
; It is sometimes useful to start the simulation with a refined equidistant grid, i.e., start creating
; the initial condition on a higher grid level. This is for example useful for expensive mask functions
; such as the µCT data. After the initial condition, the code is allowed to refine down to min_treelevel again.
; the default values is the same as min_treelevel
ini_treelevel=1;
; max number of trees in the forest. A tree corresponds to a grid; this notation
; only is important for postprocessing, i.e. using the adaptive-POD module. For running
; simulations, you can leave the value empty - it is set automatically.
max_forest_size=;
; Use adaptivity or not? If adapt_tree=1 then the grid is refined before a time step,
; the time evolution is done, and the grid is coarsened after the time step. If adapt_tree=0
; the grid does not change after the initial condition, and refinement/coarsening are disabled.
adapt_tree=1;
; adaptive initial conditon? i.e. create grid to respect error bounds
; default is same value as adapt_tree
adapt_inicond=1;
; in some situations, it is necessary to create the intial grid, and then refine it for a couple of times.
; for example if one does non-adaptive non-equidistant spatial convergence tests. default is 0.
inicond_refinements=0;
; block distribution for balancing (also used for start distribution)
; [sfc_z | sfc_hilbert]
; sfc_z  -> space filling curve -> z-curve
; sfc_hilbert -> hilbert space filling curve
block_dist=sfc_hilbert;
; refinement indicator to be used in mesh refinement [everywhere, significant]
; everywhere: refine every single block, a long proven strategy. Corresponds to what is used in Engels et al 2021 CiCP, which
;             is a conservative implementation of Liandrat's safety zone.
; significant: do not refine blocks which are not significant, this can save many blocks but is still experimental. It relies
;              on the coarsening (adapt_mesh) for figuring out which blocks are significant. Hence, only blocks with signficant
;              wavelet coeffs are refined, however, he grid still has to be graded which in turn adds some blocks again.
refinement_indicator=everywhere;
; coarsening indicator to be used in mesh adaptation (=coarsening) [threshold-state-vector, random, primary-variables]
; threshold-state-vector: evaluates wavelet criterion on components of state vector. specify below which ones.
; random: randomly coarse some blocks. used for testing. note we tag for coarsening only once in the first iteration
; everywhere: coarsenes the entire grid by one level. note that this is strictly speaking, only guranteed to be possible
; if the grid has been refined "everyhwere" before.
coarsening_indicator=threshold-state-vector;
; sometimes, it can be useful to use a different indicator to generate the initial grid. For example, we can generate
; some non-equidistant grid for inicond, then use coarsening_indicator=everywhere
; default: same as coarsening_indicator
coarsening_indicator_inicond=;
; use normalization for eps or not? Thresholding means we control the absolute error in some norm (often Linfty norm, see below)
; but very often, you rather want to control the relative error. So, some norm of the field is computed, such that
; || u-u_eps || / ||u|| < eps  (using the norm specified below)
; default=0, even though this is stupid: if you have large pressure (say u=1 and pressure=10000), then only the pressure will determine
; the grid
eps_normalized=1;
; which components to use for coarsening_indicator? default is all components individually (set to 1).
; active only if coarsening_indicator=threshold-state-vector. select the components, set as
; many as number_equations, values>1 are each treated together with a norm-equivalent.
; For example, in 3D ACM, this could be 1,1,1,1 to threshold all components individually or
; 2,2,2,1 to threshold the velocity as a vector and the pressure as a scalar, or 1,0,0,1 to base adaptation 
; on ux and p only (never used, just an example).
threshold_state_vector_component=1 1 1 1;
; it can be useful to also use the mask function (if penalization is used) for grid adaptation.
; i.e. the grid is always at the finest level on mask interfaces. Careful though: the Penalization
; is implemented on physics-module level, i.e. it is not available for all modules.
threshold_mask=1;
; if this flag is set (1), then blocks on max level have to coarsen, even if their
; details are significant. This is equivalent to ensuring dealiasing. Hence, if set to 1,
; wabbit will evaluate the right hand side of your equation on max_treelevel, but in the mesh
; coarsening it will, regardless of the solution, downsample the result to max_treelevel-1. Your
; expected precision is thus max_treelevel-1, but the computational cost (derivatives and timestep)
; is on max_treelevel.
force_maxlevel_dealiasing=1;
; if desired, we perform more than one time step
; before adapting the grid again. this can further reduce the overhead of adaptivity
; Note: the non-linear terms can create finer scales than resolved on the grid. they
; are usually filtered by the coarsening/refinement round trip. So if you do more than one time step
; on the grid, consider using a filter. default is "1", which is the classical scheme
N_dt_per_grid=1;
; coarseExtension means we delete wavelet coefficients near a coarse/fine interface. This
; allows us to skip the linear system that would occur otherwise, and it avoids artifacts
; observed with the lifted wavelets. Default=1, you shoudn't use 0
useCoarseExtension=1;
; the coarseExtension means deleting WC near the interface. However, if a significant WC travels towards
; this interface, then it may be deleted. The additional security zone (which is different from the safety
; zone = refine_everywhere) adds more blocks so that this will not happen. Default=1, you shoudn't use 0
useSecurityZone=1;


[Time]
; final time to reach in simulation
time_max=1.0;
; maximum walltime allowed for simulations (in hours). The run will be stopped if this duration
; is exceeded. This is useful on real clusters, where the walltime of a job is limited, and the
; system kills the job regardless of whether we're done or not. If WABBIT itself ends execution,
; a backup is written and you can resume the simulation right where it stopped. Note you can also
; stop a run using the file "runtime_control" (set runtime_control=save_stop;)
walltime_max=999.9;
; While we can save every write_time time units of the simulation, it may be desirable to save also
; every couple of hours of runtime (for very expensive runs) so that we can be sure to be able to
; resume the simulation with at most the loss of these hours. default unused, set value in HOURS.
walltime_write=;
; number of time steps performed. if not set, default value is very large
nt=;
; CFL criterium (velocity). Note the time step dt is dictated by the physics modules: some eqns (like
; the heat eqn, which is not implemented) may not even have a CFL restriction.
CFL=1.0;
; CFL critierum for penalization (dt<=CFL_eta*C_eta), if VPM is used. For RungeKuttaGeneric schemes, the constant
; has to be < 1.0 (otherwise the code is unstable). If you use RKC schemes,
; set this to a large value. This parameter is used by ACM physics module only.
CFL_eta=0.99;
; time step restriction of viscous terms ( dt < CFL_NU * dx**2 / nu )
; The RK4 scheme (the default!) can integrate operators with real eigenvalues up to -2.79*dt (we add a small safety
; margin 0.95). The smallest eigenvalue from the diffusion term is -4/dx**2 for the FD2, -5.333/dx**2 for FD4 and -6.044/dx**2
; for the FD6. The eigenvalue of the 2D/3D operator is then dim*Y/dx**2, with Y={4,5.333,6.044}. The default value for
; CFL_nu is therefore 0.95*2.79 / (Y*dim).
; (see nice article. https://en.wikipedia.org/wiki/Kronecker_sum_of_discrete_Laplacians)
; Note this condition is relevant for low Re only - at high Re, other terms dominate the time step. If you use RKC schemes,
; set this to a large value.
CFL_nu=;
; wabbit can save the heavy data (flow fiels) to HDF5. What is saved depends on the physics modules
; and the section [Saving]. Here you control WHEN you want to save the output: either after a fixed
; number of time steps [fixed_freq], or after a physical time interval [fixed_time]
write_method=fixed_time;
; if write_method=fixed_freq:
; write frequency for output, choose very large number for disabling output on disk
write_freq=2;
; if write_method=fixed_time:
; write time for output
write_time=0.01;
; fixed time step. if the value is greater 0.0, then the time step is fixed no matter what.
; the setting from the physics modules, which usually decide about dt, are ignored and over-
; written. The default is 0.0, so not used. NOTE: WABBIT still will adjust dt to precisely match
; the time for saving and statistics and the final time, if any of those is not a multiple of dt_fixed.
; In that case, some time steps may be smaller in order to reach those times.
dt_fixed=0.0;
; largest time step, if you want to set one. dt is always smaller than that, if the
; value is greater 0. default is 0.0, so not used. WABBIT overwrites the physics module dt
; by that value, if the timestep is larger than dt_max and dt_max > 0.
dt_max=0.0;
; time-step method. can be either "RungeKuttaGeneric" or "Krylov". In the former case,
; any explicit Runge-Kutta scheme can be set by using the Butcher-Tableau. (RK4 is default) In the latter,
; the number of Krylov subspaces M_krylov can be set.
; [ RungeKuttaGeneric, Krylov, RungeKuttaChebychev ]
time_step_method=RungeKuttaGeneric;
; The usual RungeKuttaChebychev method contains a number of hard coded schemes for different
; number of stages "s" and the fixed damping coefficient eps=10.0 (see Verwer and Sommeijer)
; if you want to use another RKC scheme, you can do so by settting it up in this INI-file.
; Provide coefficients with length "s". they are usually precomputed in python.
RKC_custom_scheme=no;
; (complicated) coefficients following Verwer & Sommeijer follow.
; longest scheme is 60 stages.
RKC_mu=;
RKC_mu_tilde=
RKC_nu=
RKC_gamma_tilde=
RKC_c=
; number of stages "s" for the RungeKuttaChebychev method. Memory is always 6 registers
; independent of stages. Default code allows up to 40 stages for eps=10.0 (hard-coded)
; coefficients. other schemes can be defined manually above.
s=10;
; if time_step_method is krylov, then you can specify the dimension of the krylov subspace
; below. If dynamic subspace dimensions are used, we interpret this number as the maximum
; number of spaces admissible (the method requires a lot of memory in general)
M_krylov=12;
; fixed or dynamic krylov subspace dimension:
; [ fixed, dynamic ]
krylov_subspace_dimension=fixed;
; if dynamic subspace dimensionality is used, provide the residuum threshold here. Note this is
; in general not an exact measure for the error, but rather a good indicator.
krylov_err_threshold=1.0e-3;
; butcher_tableau
; use your butcher_tableau for the Runge Kutta time step function
; e.g. RK4:
; butcher_tableau=(/ 0.0 0.0 0.0 0.0 0.0
; 0.5 0.5 0.0 0.0 0.0
; 0.5 0.0 0.5 0.0 0.0
; 1.0 0.0 0.0 1.0 0.0
; 0.0 0.16666666666666666 0.33333333333333331 0.33333333333333331  0.16666666666666666 /)


[Physics]
; what physics module is used?
; [ACM-new, ConvDiff-new, navier_stokes]
physics_type=ACM-new;
; decide if you want to start from a given configuration (i.e. Statevector)
; 1:true, 0:false and we start from the initial conditions dictated by the physics
; modue.
read_from_files=0;
; if read_from_files is true, WABBIT will try to start from the given files
input_files=rho_000000000141.h5 Ux_000000000141.h5 Uy_000000000141.h5 p_000000000141.h5;


[Saving]
; WABBIT is in charge of saving, but what is saved is controled by the physics modules.
; here, you need to tell WABBIT how many fields are saved and how they will be labeled.
; The physics modules are then in charge of providing the respective data to WABBIT. I.e.
; if the field is called "mask", WABBIT will ask the physics module to return the array
; "mask" and then save that to disk.
; how many fields are you going to save?
N_fields_saved=6;
; how are the fields labeled?
field_names=ux uy uz p mask scalar1;


[Statistics]
; save every nsave time steps (leave empty to disable)
nsave_stats=10;
; and every tsave physical time units (leave empty to disable)
tsave_stats=0.20;


[ACM-new]
; speed of sound, used also for the CFL condition. The characteristic velocity is
; u_eigen = umax + sqrt(umax**2 + c0**2)
c_0=50.0;
; viscosity. We also respect the time step constraint imposed by explicit diffusion
nu=1e-2;
; damping term for pressure, see [Ohwada, Asinari, JCP2010]. This coefficent is a dashpot-like damping,
; dp/t = ... -gamma*p and it is used primarily for purely periodic flows without penalization (i.e.
; without boundary conditions: an example would be Taylor-Green Vortices)
gamma_p=1;
; mean flow, is imposed as initial condition (if inicond=meanflow) and in the sponge
; layer as far-field BC (if this is used!)
u_mean_set=0.0 0.0 0.0;
; initial condition
inicond=meanflow;
; if inicond= pressure-blob, this is the size of the blob.
; if inicond=noise, this is the upper value for the noise (beta*rand(0..1))
beta=0.05;
; we can use passive scalars with the ACM. their parameters are specified in "ConvectionDiffusion" below
; but they need to be turned on here. Default is off.
use_passive_scalar=0;
; sometimes, but very rarely, we want to compute just the passive scalar and not
; the flow field, because the convection-diffusion physics module does not contain the
; penalized passive scalar eqns.
compute_flow=1;
;
use_HIT_linear_forcing=0;
; use skew-symmetric discretization or not? Default=false at the moment. Note if it equals false, you should
; probably use force_maxlevel_dealiasing=1 depending on resolution and viscosity - otherwise the simulation
; becomes unstable. With the skew_symmetry=1, the solution is stable even if nu=0.0 (inviscid case), and you
; do not need to set force_maxlevel_dealiasing=1 (and you really shouldn't)
skew_symmetry=1;
; ACM Model for the pressure eqn: 
; "acm": [Chorin1967]  (default, usual eqn as used in [Engels CICP 2021]) 
; "diffusive": [Clausen2013, Dupuy2020] (pressure diffusion with same nu as usual viscosity)
; "convective": [Clausen2013, Dupuy2020] 
; "EDAC": [Clausen2013, Dupuy2020] (Is the sum of "diffusive" and "convective")
; "bulk_viscosity" : [Yasuda2023, AbdulGafoor2024] 
p_eqn_model=;
; bulk viscosity
bulk_viscosity=0.0;

[Sponge]
; sponge term, used in ACM module to mimick outflow conditions for pressure waves
; NOTE (ACM): when the sponge is used, be sure to allow for mask_time_dependent_part=1. Even
; though the sponge function is not explicitly time-dependent, it is treated as such because
; the sponge does not have to be at the maximum refinement level.
use_sponge=0;
; shape of the sponge. the tradional form (default) is "rect", but we have a smoothed
; version with round corners which is called "p-norm". It has the parameter p_sponge,
; which controls the roundedness of corners. The function is inspired by the p-norm
; ((x-x0)**p + (y-y0)**p + (z-z0)**p)**1/p [https://de.wikipedia.org/wiki/P-Norm]
; a good compromise is p=8.0
; choices: rect, rect-symmetry-y, rect-symmetry-yz, inlet-outlet-x, p-norm, p-norm-insect-centered
sponge_type=rect;
; p-sponge is used only in conjunction with sponge_type=p-norm;
p_sponge=8.0;
; thickness of sponge layer (in physial units)
L_sponge=0.1;
; sponge damping constant
C_sponge=1.0e-2;


[ConvectionDiffusion]
; adding passive scalars to the flow. (tracers / odors)
; how many scalar fields do you want to solve? Each scalar requires solving an equation and
; this the number_equations = N_fluid + N_scalars, N_fluid = 3 (2d) or 4 (3d)
N_scalars=0;
; --------------------------------------------------------------------------------
; note you need to specify one value per scalar field for ALL the below parameters
; --------------------------------------------------------------------------------
; viscosity. if nu<1.0e-10 (or 0.0), diffusion is disabled. NOTE: if coupled to ACM,
; provide Schmidt number instead of nu
nu=0.0e-6;
; if ConvectionDiffusion is run together with ACM, you specify the Schmidt number below
; and NOT the viscosity nu
Sc=1.0 1.0;
; initial condition for the scalar(s)
inicond=empty empty;
; source for scalars. "gaussian": at the point specified below, a source term.
; "mask_color_emission": scalar is emmited at mask parts with the color specified in widthsource
; (which in this case is no longer the width)
; each entry has N_scalars values.
source=gaussian gaussian;
x0source=1 2;
y0source=1 1;
z0source=0 0;
; width of "gaussian" or color of "mask_color_emission"
widthsource=0.2 0.1;
; the penalization for the scalar is independent of that of the fluid for the neumann
; no-flux BC on the obstacles. For Dirichlet sources, the usual [VPM]::C_eta is used.
C_eta=1e-3 1.e-3;
; sponges are used to impose dirichlet BC at domain borders: for the passive scalar,
; you have to choice to activate this or not. If set, scalars are absorbed in the sponge
; layer
absorbing_sponge=1;
; The BC can either be "neumann" (adiabatic, no flux) or "dirichlet" (isothermic, fixed concentration)
; default is neumann
scalar_BC_type=neumann;


[Discretization]
; order of derivatives [ FD_2nd_central, FD_4th_central, FD_6th_central, FD_4th_central_optimized ]
order_discretization=FD_4th_central;
; explicit filtering of state vector, after time evolution (and before coarsening).
; available filters: [explicit_3pt, explicit_5pt, explicit_7pt, explicit_9pt, explicit_11pt]
filter_type=;
; filter frequency (note: set filter to no_filter if you want to disable filtering completely)
; Note our clumsy nomenclature: we mean filtering every "filter_freq" time steps
filter_freq=10;


[VPM]
; Volume penalization method to take obstacles into account without adapting the
; grid. Penalization is an equation-dependent addon. It can not be used with any
; RHS, if the RHS does not support it.
; flag for penalization (0/1)
penalization=1;
; WABBIT needs to know about the mask function (if penalization is used): does it contain
; a time-dependent-part (e.g. moving obstacles, time-dependent forcing)? does it contain
; a time-independent part (fixed walls, homogeneous forcing)? or both? WABBIT needs to know
; that since we try to create the time-independent mask function only once, but the time-dependent
; part of course in every time step.
; NOTE: the flag threshold_mask has a critical impact here: if it is false, it is not guaranteed that the
; fluid-solid interface is on Jmax or Jmax-1, hence the technique of using a pre-generated static mask function
; that can be added to the time-dependent part cannot be used. If the mask function is expensive to compute,
; ensure that threshold_mask is set.
mask_time_dependent_part=1;
mask_time_independent_part=1;
dont_use_pruned_tree_mask=0;
; smooth mask for penalization term [0,1]. If the obstacle moves, this flag should
; be set, and in static cases as well. hard masks with only 0 and 1 are deprecated but
; included for completeness. Note some mask functions may ignore this flag (the insects for example)
smooth_mask=1;
; penalization factor. Can be seen as porosity, so smaller values = harder walls
; Note for explicit time integration, dt < C_eta
C_eta=1e-3;
; [none, Insect, cylinder, two-cylinders, rotating_cylinder, 2D-wingsection, sphere-fixed, sphere-free,
; lamballais]
; if "Insect" all other parameters are read from "Insect" section.
geometry=triangle;
; center coordinate of object
x_cntr=0.5 0.5 0;
; [triangle,rhombus,cylinder, sphere]: length or diameter of the object
length=1.0;
; the "thickness" is used by geometry=2D-plate
thickness=1.0;
; if geometry==2D-wingsection then this INI file is used to determine its kinematics:
; this is a vector, we can run many wingsections (typically, two are used)
wingsection_inifiles=none.ini;
; smoothing constant (smoothing layer is propotional to dx_min)
; Note: insect module uses its own [Insects::C_smooth]
C_smooth=1.5;
; Parameters for 2D lamballais test case (used only if geometry==lamballais)
; Gautier, R., Biau, D., Lamballais, E.: A reference solution of the flow over a circular cylinder at Re = 40 , Computers & Fluids 75, 103–111, 2013 
R0=0.50;
R1=1.75;
R2=2.25;
file_usx=
file_usy=
file_usp=
smoothing_type=hester; hester, discontinuous/dis, cos
; EXPERIMENTAL:
; Soft penalization: gently turn on penalization at the beginning (t=0) of a simulation. This makes the initial wave 
; travelling through the domain smoother. Its thickness is usually C_eta*C_0 (dimension L). Slowly decreasing C_eta from C_eta_start=1.0
; to its final value (small, say C_eta=1e-4) thus drastically increases the shock width. The shock intensity decays as R^-1 (2D) or 
; R^-2 (3D), but even in 3D it can still require resolution of the shock wave that can be expensive. 
; The function C_eta(t) in this case is an exponential decay from C_eta_start to C_eta.
soft_penalization_startup=no;
C_eta_start=1.0;
penalization_startup_tau=0.20;
; default for C_eta_ring is C_eta, leave empty for global variation of Lamballais-test case
C_eta_ring=;

[Insects]
; NOTE: Those parameters are used only in ACM and only if VPM::geometry=Insect
;-------------------------------------------------------------------------------
; Body geometry
x_pivot_r=0.0 0.0 0.0; (vector) position of right wing in body system
x_pivot_l=0.0 0.0 0.0; (vector) position of left wing in body system
; Body (types: ellipsoid, drosophila, nobody, superSTL, sphere) if free sphere in geometry use sphere
BodyType=nobody;
; if the body is a superSTL file, specify the filename here. Note: the geometry
; is understood in the body frame of reference, hence 0,0,0 is the centre of the body
; (which does in our notation imply the centre of gravity there, but this is relevant
; only in free-fight, and the superSTL option is currently only used for tethered flight)
BodySuperSTLfile=;
RightWing=yes;
LeftWing=no;
; if the insect has a fore- and hind wing, we end up with a four-winged insect
RightWing2=no;
LeftWing2=no;
J_body_yawpitchroll=1.0 1.0 1.0; Body moment of inertia in body reference frame
; total mass of animal, in appropriate dimensions. As rho_fluid is usually 1.0
; and the wing length R=1.0, the unit here would be M=rho_f*R^3
mass=1.0;
; if using the free-flight solver, specify the gravitational acceleration.
; gravity = in z-direction, specify x and y direction (if ever nonzero)
; separately.
gravity=1.0; negative: falling in negative z-direction
gravity_x=; usually zero
gravity_y=; usually zero
;-------------------------------------------------------------------------------
; Wing geometry (Shapes: rectangular, TwoEllipses, drosophila, drosophila_mutated,
; drosophila_sandberg, drosophila_maeda, flapper_sane)
; You can also set WingShape=from_file::wing_shape.ini to read the wing geometry
; from an INI file. In the latter case, generic Fourier and rectangular wings with
; and without bristles are available.
WingShape=suzuki;
b_top=0.1; if WingShape=TwoEllipses, that's thickness of the forward one
b_bot=0.3; if WingShape=TwoEllipses, that's thickness of the backward one
L_chord=1.0;
; wing tickness (from top to bottom surface, not divided by two)
; note if you use WingShape=from_file:: then the thickness is possibly overwritten
; by the value in this ini file. If the value is not found in the file, the one given
; here is used.
WingThickness=0.0417;
; wing inertia tensor (used to compute inertial power)
Jxx=0.0560;
Jyy=0.0031;
Jzz=0.0591;
Jxy=0.0061;
;-------------------------------------------------------------------------------
; Body motion
; motion of the body: (tethered, free_flight, yawpitchroll_param)
BodyMotion=tethered;
x0=2 2 2; initial (or tethered) position
v0=0 0 0; inital velocity
yawpitchroll_0=45.0 -45.0 0.0; initial (or tethered, or time-average) orientation in degrees
yawpitchroll_a1=0.0 15.0 0.0; if BodyMotion=yawpitchroll_param first cosine harmonic component
yawpitchroll_b1=0.0 10.0 0.0; if BodyMotion=yawpitchroll_param first sine harmonic component
eta0=-45.00; stroke plane angle in degrees
DoF=000000; x,y,z,yaw,pitch,roll DoF on=1 or off=0
;-------------------------------------------------------------------------------
; Wing motion
; (types: Drosophila_hovering_fry, Drosophila_hovering_maeda, flapper_sane,
; flapper_dickinson, takeoff, simplified, from_file, none)
FlappingMotion_right=suzuki;
FlappingMotion_left=suzuki;
; if flappingmotion=="from_file", which file to use?
infile=bumblebee_new_kinematics.ini;
;-------------------------------------------------------------------------------
; The fractal tree module is a submodule of the insect module. We can also simulate
; an insect together with a fractal tree
fractal_tree=no;
; a fractal tree is a list of cylinders. They are given in a simple ascii-file
; without header, containing one cylinder per line. The colums then are
; x1,y1,z1,x2,y2,z2,R
; so last column is radius and not diameter. We re-define the cylinder such that the
; origin of the very first one is at (/0,0,0/) before adding fractal_tree_x0
fractal_tree_file=tree_data.in;
; The fractal tree as a whole can be translated
fractal_tree_x0=0.0, 0.0, 0.0;
; we can scale the whole tree up as well:
fractal_tree_scaling=1.0;
; fractal tree cylinders can have endpoint spheres (default) or be sharply cut, finite cylinder
; like in [Yin, Onishi, Watanabe et al, JFM2025].
fractal_tree_spheres=1;
;-------------------------------------------------------------------------------
; Parameters that control the smoothing of the mask function
; Discovered that this was done block based, i.e. the smoothing layer
; had different thickness, if some blocks happened to be at different levels (and still carry
; a part of the smoothing layer.) I don't know if that made sense, because the layer shrinks/expands then
; and because it might be discontinous. Both options are included now, default is "as before"
; Insect%smoothing_thickness=="local"  : smoothing_layer = c_sm * 2**-J * L/(BS-1)
; Insect%smoothing_thickness=="global" : smoothing_layer = c_sm * 2**-Jmax * L/(BS-1)
smoothing_thickness=; default: local
C_smooth=; default: 1.0
; when using CT data, code computes the mask function in a shell around fluid-solid interface.
; The tickness of the shell is not a critical parameter, but it affects performance. Thicker shell
; means more points and thus more comput effort. It is given in multiples of C_smooth, that means
; shell_thickness = C_shell_thickness * dx_min
; Note: for dry-runs, it is
C_shell_thickness=; default: 3.0


[FreeFlightSolver]
; The free-flight solver is a part of the Insects module (although we can use it for
; canonical simulations such as a falling sphere, which we think of as degenerate insect).
; It can only be used with the ACM. If used, ACM rhs computes the aerodyn. forces and moments
; in every RHS evaluation (several times per time step). This is not expensive but still
; we do not do it if its not necessary.
; Note you can use the free-flight solver only with:
; time_step_method=RungeKuttaGeneric-FSI;
; geometry=Insect;
use_free_flight_solver=0;


[Debug]
; check if the ghost node synchronization gives the right order, on a random
; grid. this test costs some CPU time but no memory. It is done only once at startup.
test_ghost_nodes_synch=1;
test_treecode=0;
test_wavelet_decomposition=0;
